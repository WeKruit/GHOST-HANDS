{
  "$schema": "./models.config.schema.json",
  "version": 1,

  "providers": {
    "siliconflow": {
      "name": "SiliconFlow",
      "baseUrl": "https://api.siliconflow.cn/v1",
      "envKey": "SILICONFLOW_API_KEY",
      "docs": "https://docs.siliconflow.cn/en/userguide/capabilities/vision"
    },
    "deepseek": {
      "name": "DeepSeek",
      "baseUrl": "https://api.deepseek.com/v1",
      "envKey": "DEEPSEEK_API_KEY",
      "docs": "https://platform.deepseek.com/docs"
    },
    "moonshot": {
      "name": "Moonshot (Kimi)",
      "baseUrl": "https://api.moonshot.ai/v1",
      "envKey": "MOONSHOT_API_KEY",
      "docs": "https://platform.moonshot.ai/docs"
    },
    "minimax": {
      "name": "MiniMax",
      "baseUrl": "https://api.minimax.io/v1",
      "envKey": "MINIMAX_API_KEY",
      "docs": "https://platform.minimax.io/docs/api-reference/text-openai-api"
    },
    "openai": {
      "name": "OpenAI",
      "baseUrl": "https://api.openai.com/v1",
      "envKey": "OPENAI_API_KEY",
      "docs": "https://platform.openai.com/docs"
    },
    "anthropic": {
      "name": "Anthropic",
      "envKey": "ANTHROPIC_API_KEY",
      "docs": "https://docs.anthropic.com/"
    },
    "zhipu": {
      "name": "Zhipu AI (ChatGLM)",
      "baseUrl": "https://open.bigmodel.cn/api/paas/v4/",
      "envKey": "ZHIPU_API_KEY",
      "docs": "https://open.bigmodel.cn/dev/api/thirdparty-frame/openai-sdk"
    },
    "qwen-alibaba": {
      "name": "Alibaba Cloud (Qwen)",
      "baseUrl": "https://dashscope-intl.aliyuncs.com/compatible-mode/v1",
      "envKey": "DASHSCOPE_API_KEY",
      "docs": "https://help.aliyun.com/zh/model-studio/developer-reference/compatibility-of-openai-with-dashscope"
    },
    "google": {
      "name": "Google AI",
      "baseUrl": "https://generativelanguage.googleapis.com/v1beta/openai",
      "envKey": "GOOGLE_API_KEY",
      "docs": "https://ai.google.dev/gemini-api/docs"
    }
  },

  "models": {
    "qwen-7b": {
      "provider": "siliconflow",
      "model": "Qwen/Qwen2.5-VL-7B-Instruct",
      "vision": true,
      "cost": { "input": 0.05, "output": 0.15, "unit": "$/M tokens" }
    },
    "qwen-32b": {
      "provider": "siliconflow",
      "model": "Qwen/Qwen2.5-VL-32B-Instruct",
      "vision": true,
      "cost": { "input": 0.26, "output": 0.78, "unit": "$/M tokens" }
    },
    "qwen-72b": {
      "provider": "siliconflow",
      "model": "Qwen/Qwen2.5-VL-72B-Instruct",
      "vision": true,
      "cost": { "input": 0.25, "output": 0.75, "unit": "$/M tokens" }
    },
    "qwen3-8b": {
      "provider": "siliconflow",
      "model": "Qwen/Qwen3-VL-8B-Instruct",
      "vision": true,
      "cost": { "input": 0.07, "output": 0.27, "unit": "$/M tokens" }
    },
    "qwen3-32b": {
      "provider": "siliconflow",
      "model": "Qwen/Qwen3-VL-32B-Instruct",
      "vision": true,
      "cost": { "input": 0.14, "output": 0.55, "unit": "$/M tokens" }
    },
    "qwen3-235b": {
      "provider": "siliconflow",
      "model": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "vision": true,
      "cost": { "input": 0.34, "output": 1.37, "unit": "$/M tokens" }
    },
    "deepseek-chat": {
      "provider": "deepseek",
      "model": "deepseek-chat",
      "vision": false,
      "cost": { "input": 0.28, "output": 0.42, "unit": "$/M tokens" },
      "note": "No vision support; works with accessibility tree only"
    },
    "deepseek-reasoner": {
      "provider": "deepseek",
      "model": "deepseek-reasoner",
      "vision": false,
      "cost": { "input": 0.55, "output": 2.19, "unit": "$/M tokens" },
      "note": "No vision support; reasoning model"
    },
    "kimi-8k": {
      "provider": "moonshot",
      "model": "moonshot-v1-8k-vision-preview",
      "vision": true,
      "cost": { "input": 0.60, "output": 3.00, "unit": "$/M tokens" }
    },
    "kimi-32k": {
      "provider": "moonshot",
      "model": "moonshot-v1-32k-vision-preview",
      "vision": true,
      "cost": { "input": 0.60, "output": 3.00, "unit": "$/M tokens" }
    },
    "kimi-128k": {
      "provider": "moonshot",
      "model": "moonshot-v1-128k-vision-preview",
      "vision": true,
      "cost": { "input": 0.60, "output": 3.00, "unit": "$/M tokens" }
    },
    "minimax-vl": {
      "provider": "minimax",
      "model": "MiniMax-VL-01",
      "vision": true,
      "cost": { "input": 0.20, "output": 1.10, "unit": "$/M tokens" }
    },
    "minimax-m2.5": {
      "provider": "minimax",
      "model": "MiniMax-M2.5",
      "vision": false,
      "cost": { "input": 0.20, "output": 1.10, "unit": "$/M tokens" }
    },
    "gpt-4o": {
      "provider": "openai",
      "model": "gpt-4o",
      "vision": true,
      "cost": { "input": 2.50, "output": 10.00, "unit": "$/M tokens" }
    },
    "gpt-4o-mini": {
      "provider": "openai",
      "model": "gpt-4o-mini",
      "vision": true,
      "cost": { "input": 0.15, "output": 0.60, "unit": "$/M tokens" }
    },
    "claude-sonnet": {
      "provider": "anthropic",
      "model": "claude-sonnet-4-6",
      "vision": true,
      "cost": { "input": 3.00, "output": 15.00, "unit": "$/M tokens" }
    },
    "claude-haiku": {
      "provider": "anthropic",
      "model": "claude-haiku-4-5-20251001",
      "vision": true,
      "cost": { "input": 0.80, "output": 4.00, "unit": "$/M tokens" }
    },
    "glm-5": {
      "provider": "zhipu",
      "model": "glm-5",
      "vision": true,
      "cost": { "input": 0.50, "output": 0.50, "unit": "$/M tokens" },
      "note": "Zhipu AI GLM-5, supports vision via OpenAI-compatible API"
    },
    "qwen3-vl-235b-thinking": {
      "provider": "siliconflow",
      "model": "Qwen/Qwen3-VL-235B-A22B-Thinking",
      "vision": true,
      "cost": { "input": 0.45, "output": 3.50, "unit": "$/M tokens" },
      "note": "Frontier VL reasoning. Chain-of-thought + vision. Best accuracy for complex GUI automation."
    },
    "qwen3-vl-30b-thinking": {
      "provider": "siliconflow",
      "model": "Qwen/Qwen3-VL-30B-A3B-Thinking",
      "vision": true,
      "cost": { "input": 0.29, "output": 1.00, "unit": "$/M tokens" },
      "note": "MoE 30B/3B active. Vision + thinking at fraction of 235B cost."
    },
    "qwen3-vl-30b": {
      "provider": "siliconflow",
      "model": "Qwen/Qwen3-VL-30B-A3B-Instruct",
      "vision": true,
      "cost": { "input": 0.29, "output": 1.00, "unit": "$/M tokens" },
      "note": "MoE 30B/3B active. Fast vision without thinking overhead."
    },
    "qwen3-235b-thinking": {
      "provider": "siliconflow",
      "model": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "vision": false,
      "cost": { "input": 0.35, "output": 1.42, "unit": "$/M tokens" },
      "note": "Text-only reasoning. Use when vision not needed. 256K context."
    },
    "qwen3-coder-480b": {
      "provider": "siliconflow",
      "model": "Qwen/Qwen3-Coder-480B-A35B-Instruct",
      "vision": false,
      "cost": { "input": 0.25, "output": 1.00, "unit": "$/M tokens" },
      "note": "480B code model. Best for form-fill code generation and browser agent scripting."
    },
    "qwen3-next-80b": {
      "provider": "siliconflow",
      "model": "Qwen/Qwen3-Next-80B-A3B-Thinking",
      "vision": false,
      "cost": { "input": 0.14, "output": 0.57, "unit": "$/M tokens" },
      "note": "Ultra-fast reasoning. 10x throughput vs Qwen3-32B. MoE 80B/3B active."
    },
    "gpt-4.1": {
      "provider": "openai",
      "model": "gpt-4.1",
      "vision": true,
      "cost": { "input": 2.00, "output": 8.00, "unit": "$/M tokens" }
    },
    "gpt-5.2": {
      "provider": "openai",
      "model": "gpt-5.2",
      "vision": true,
      "cost": { "input": 1.75, "output": 14.00, "unit": "$/M tokens" }
    },
    "claude-opus": {
      "provider": "anthropic",
      "model": "claude-opus-4-6",
      "vision": true,
      "cost": { "input": 5.00, "output": 25.00, "unit": "$/M tokens" },
      "note": "#1 on intelligence leaderboards. Adaptive reasoning. Best for complex multi-step form flows."
    },
    "gemini-2.5-flash": {
      "provider": "google",
      "model": "gemini-2.5-flash-preview-04-17",
      "vision": true,
      "cost": { "input": 0.15, "output": 0.60, "unit": "$/M tokens" },
      "note": "Fast, cheap, decent accuracy. Good for high-volume simple forms."
    },
    "gemini-2.5-pro": {
      "provider": "google",
      "model": "gemini-2.5-pro-preview-05-06",
      "vision": true,
      "cost": { "input": 1.25, "output": 10.00, "unit": "$/M tokens" },
      "note": "Strong vision and reasoning. 1M context window."
    },
    "gemini-2.0-flash": {
      "provider": "google",
      "model": "gemini-2.0-flash",
      "vision": true,
      "cost": { "input": 0.10, "output": 0.40, "unit": "$/M tokens" },
      "note": "Ultra-fast Gemini. Good for simple vision tasks."
    }
  },

  "presets": {
    "speed": {
      "description": "Fastest and cheapest -- good for rapid iteration and testing",
      "model": "qwen-7b"
    },
    "balanced": {
      "description": "Best accuracy-per-dollar -- MoE 235B with strong vision",
      "model": "qwen3-235b"
    },
    "quality": {
      "description": "Frontier accuracy -- VL thinking model, chain-of-thought GUI reasoning",
      "model": "qwen3-vl-235b-thinking"
    },
    "premium": {
      "description": "OpenAI GPT-5.2 -- frontier reasoning, multimodal",
      "model": "gpt-5.2"
    }
  },

  "default": "qwen-72b"
}
